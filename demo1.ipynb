{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240, 240, 155)\n"
     ]
    }
   ],
   "source": [
    "#数据读取\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, interactive, IntSlider, ToggleButtons\n",
    "imgPath=r\"G:\\ZMZ\\数据集\\Brarts\\Brats测试结果\\hgg_BraTS19_CBICA_AUA_1.nii.gz\"\n",
    "imageLoad=nib.load(imgPath)\n",
    "imageData=imageLoad.get_fdata()\n",
    "type(imageData)\n",
    "print(imageData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"import SimpleITK as sitk\\n\\n# 加载原始nii文件\\nimage = sitk.ReadImage('path/to/image.nii')\\n\\n# 将高度维度填充至64\\nimage_data = sitk.GetArrayFromImage(image)\\npadded_data = pad_3d_volume_along_axis(image_data, axis=1, target_size=64)\\n\\n# 将填充后的数据保存为新的nii文件\\npadded_image = sitk.GetImageFromArray(padded_data)\\npadded_image.CopyInformation(image)\\nsitk.WriteImage(padded_image, 'path/to/padded_image.nii')\""
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#归一化\n",
    "def normalize(slice, bottom=99, down=1):\n",
    "    \"\"\"\n",
    "    normalize image with mean and std for regionnonzero,and clip the value into range\n",
    "    :param slice:\n",
    "    :param bottom:\n",
    "    :param down:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    b = np.percentile(slice, bottom)\n",
    "    # print(b)\n",
    "    t = np.percentile(slice, down)\n",
    "    # print(t)\n",
    "    slice = np.clip(slice, t, b)\n",
    "    # print(slice)\n",
    "    image_nonzero = slice[np.nonzero(slice)]\n",
    "    if np.std(slice) == 0 or np.std(image_nonzero) == 0:\n",
    "        return slice\n",
    "    else:\n",
    "        tmp = (slice - np.mean(image_nonzero)) / np.std(image_nonzero)\n",
    "        # since the range of intensities is between 0 and 5000 ,\n",
    "        # the min in the normalized slice corresponds to 0 intensity in unnormalized slice\n",
    "        # the min is replaced with -9 just to keep track of 0 intensities\n",
    "        # so that we can discard those intensities afterwards when sampling random patches\n",
    "        tmp[tmp == tmp.min()] = -9\n",
    "        return tmp\n",
    "#裁剪    \n",
    "# def crop_ceter(img,croph,cropw):   \n",
    "#     #for n_slice in range(img.shape[0]):\n",
    "#     height,width = img[0].shape \n",
    "#     starth = height//2-(croph//2)\n",
    "#     startw = width//2-(cropw//2)        \n",
    "#     return img[:,starth:starth+croph,startw:startw+cropw]\n",
    "\n",
    "#将三维医学图像数据裁剪为某个固定尺寸\n",
    "def crop_ceter(data,target_size):\n",
    "    # 计算裁剪的起始位置和结束位置\n",
    "    start_index = [(data.shape[i] - target_size[i]) // 2 for i in range(3)]\n",
    "    end_index = [start_index[i] + target_size[i] for i in range(3)]\n",
    "    # 裁剪原始医学图像数据\n",
    "    cropped_image = data[start_index[0]:end_index[0], start_index[1]:end_index[1], start_index[2]:end_index[2]]\n",
    "    \n",
    "    return cropped_image\n",
    "\n",
    "#将三维医学图像数据填充为某个固定尺寸\n",
    "def pad_volume_to_shape(volume, shape):\n",
    "    assert len(volume.shape) == len(shape), \"Input volume and target shape have different dimensions\"\n",
    "\n",
    "    padded_volume = np.zeros(shape)\n",
    "    diff = np.asarray(shape) - np.asarray(volume.shape)\n",
    "    assert (diff >= 0).all(), \"Target shape is smaller than input volume shape\"\n",
    "\n",
    "    pad_before = diff // 2\n",
    "    pad_after = diff - pad_before\n",
    "\n",
    "    slices = tuple(slice(pb, shape[i] - pa) for i, (pb, pa) in enumerate(zip(pad_before, pad_after)))\n",
    "    padded_volume[slices] = volume\n",
    "\n",
    "    return padded_volume\n",
    "\n",
    "#实现将三维医学图像数据中的某个维度进行填充\n",
    "def pad_3d_volume_along_axis(volume, axis, target_size):\n",
    "    \"\"\"\n",
    "    在三维体积数据的某个轴上进行填充\n",
    "    :param volume: 三维体积数据,numpy数组,形状为(d, h, w)\n",
    "    :param axis: 希望进行填充的轴,可以是0, 1, 2,分别代表深度、高度、宽度\n",
    "    :param target_size: 目标大小,int类型\n",
    "    :return: 填充后的三维体积数据,numpy数组,形状为(d', h', w')\n",
    "    \"\"\"\n",
    "    size = volume.shape\n",
    "    if size[axis] > target_size:\n",
    "        raise ValueError(\"The target size should be larger than the current size along the chosen axis.\")\n",
    "    pad_size = target_size - size[axis]\n",
    "    pad_width = [(0, 0), (0, 0), (0, 0)]\n",
    "    pad_width[axis] = (pad_size // 2, pad_size - pad_size // 2)\n",
    "    return np.pad(volume, pad_width, mode='constant', constant_values=0)\n",
    "\n",
    "#数据标签集掩码处理\n",
    "def load_label_t1w(mask_path,t1w_path,label_path):\n",
    "    t1w_data = nib.load(t1w_path).get_fdata()\n",
    "    mask_data = nib.load(mask_path).get_fdata()\n",
    "    mask_np = np.array(mask_data)\n",
    "    label_data = nib.load(label_path).get_fdata()\n",
    "    label_np = np.array(label_data)\n",
    "    print(label_np.dtype)\n",
    "    label_np[label_np==4] = 0\n",
    "    label_np[label_np==5] = 0\n",
    "    label_np[label_np==6] = 0\n",
    "    t1w_mask = np.multiply(t1w_data,mask_np)\n",
    "    print(np.unique(label_np))\n",
    "    return t1w_mask,label_np\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "[0. 1. 2. 3.]\n",
      "(182, 218, 182)\n",
      "(182, 218, 182)\n",
      "(160, 160, 160)\n",
      "(160, 160, 160)\n",
      "(200, 160, 160)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, interactive, IntSlider, ToggleButtons\n",
    "imgPath=r\"E:\\DBB\\sub-0415\\dt-neuro-anat-t1w.id-61b283327de472d3390c19b4\\t1.nii.gz\"\n",
    "mask_path=r\"E:\\DBB\\sub-0415\\dt-neuro-mask.id-61b282c552911e175a11ee49\\mask.nii.gz\"\n",
    "label_path=r\"E:\\DBB\\sub-0415\\dt-neuro-parcellation-volume.id-61b282b852911e175a11ec74\\parc.nii.gz\"\n",
    "t1w_mask,label_np=load_label_t1w(mask_path,imgPath,label_path)\n",
    "print(t1w_mask.shape)\n",
    "print(label_np.shape)\n",
    "imageData=normalize(imageData)\n",
    "target_size = [160,160,160]\n",
    "data=crop_ceter(imageData,target_size)#数据裁剪\n",
    "mask=crop_ceter(label_np,target_size)\n",
    "print(data.shape)\n",
    "print(mask.shape)\n",
    "padded_data = pad_3d_volume_along_axis(data, axis=0, target_size=200)#对某一维数据进行填充\n",
    "print(padded_data.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "0\n",
      "0\n",
      "step_z 0\n",
      "19 16 160 160\n",
      "(16, 160, 160, 1)\n",
      "(16, 160, 160, 1)\n",
      "(16, 160, 160, 1)\n",
      "(16, 160, 160, 1)\n",
      "(16, 160, 160, 1)\n",
      "(16, 160, 160, 1)\n",
      "(16, 160, 160, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhao'ming'zhang\\AppData\\Local\\Temp\\ipykernel_22320\\1699466307.py:56: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  fourmodelimagearray = np.zeros((imagez, height, width, 1), np.float)\n",
      "C:\\Users\\zhao'ming'zhang\\AppData\\Local\\Temp\\ipykernel_22320\\1699466307.py:68: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  t1image = t1image.astype(np.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 160, 160, 1)\n",
      "(16, 160, 160, 1)\n",
      "(16, 160, 160, 1)\n",
      "(16, 160, 160, 1)\n",
      "(16, 160, 160, 1)\n",
      "(16, 160, 160, 1)\n",
      "(16, 160, 160, 1)\n",
      "(16, 160, 160, 1)\n",
      "(16, 160, 160, 1)\n",
      "(16, 160, 160, 1)\n",
      "(16, 160, 160, 1)\n",
      "(16, 160, 160, 1)\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#数据分块\n",
    "BLOCKSIZE=(16, 160, 160)#数据分块大小\n",
    "patch_block_size = BLOCKSIZE#BLOCKSIZE = (16, 160, 160) #每个分块的大小\n",
    "numberxy = patch_block_size[1]#160\n",
    "numberz = 8#patch_block_size[0]\n",
    "width = np.shape(data)[1]#160\n",
    "height = np.shape(data)[2]#160\n",
    "imagez = np.shape(data)[0]#160\n",
    "block_width = np.array(patch_block_size)[1]#160\n",
    "block_height = np.array(patch_block_size)[2]#160\n",
    "blockz = np.array(patch_block_size)[0]#16\n",
    "stridewidth = (width - block_width) // numberxy#0\n",
    "strideheight = (height - block_height) // numberxy#0\n",
    "stridez = (imagez - blockz) // numberz#18\n",
    "print(stridez)\n",
    "step_width = width - (stridewidth * numberxy + block_width)#0\n",
    "step_width = step_width // 2#0\n",
    "print(step_width)\n",
    "step_height = height - (strideheight * numberxy + block_height)#0\n",
    "step_height = step_height // 2\n",
    "print(step_height)\n",
    "step_z = imagez - (stridez * numberz + blockz)\n",
    "step_z = step_z // 2\n",
    "print('step_z',step_z)#0\n",
    "hr_samples_t1_list = []\n",
    "# hr_samples_flair_list = []\n",
    "# hr_samples_t1ce_list = []\n",
    "# hr_samples_t2_list = []\n",
    "hr_mask_samples_list = []\n",
    "patchnum = []\n",
    "for z in range(step_z, numberz * (stridez + 1) + step_z, numberz):\n",
    "    for x in range(step_width, numberxy * (stridewidth + 1) + step_width, numberxy):\n",
    "        for y in range(step_height, numberxy * (strideheight + 1) + step_height, numberxy):\n",
    "            if np.max(mask[z:z + blockz, x:x + block_width, y:y + block_height]) != 0:#这里要判断这个分块对应的mask标签是不是背景\n",
    "                # print(\"切%d\"%z)\n",
    "                patchnum.append(z)\n",
    "                #这里注释掉，是因为这个数据只有1个T1,不是4种模态\n",
    "                hr_samples_t1_list.append(data[z:z + blockz, x:x + block_width, y:y + block_height])\n",
    "                hr_mask_samples_list.append(mask[z:z + blockz, x:x + block_width, y:y + block_height])\n",
    "                # hr_samples_flair_list.append(flair_crop[z:z + blockz, x:x + block_width, y:y + block_height])\n",
    "                # hr_samples_t1ce_list.append(t1ce_crop[z:z + blockz, x:x + block_width, y:y + block_height])\n",
    "                # hr_samples_t2_list.append(t2_crop[z:z + blockz, x:x + block_width, y:y + block_height])\n",
    "#这里跟上边相同，也是只有一种模态\n",
    "samples_t1 = np.array(hr_samples_t1_list).reshape((len(hr_samples_t1_list), blockz, block_width, block_height))\n",
    "mask_samples = np.array(hr_mask_samples_list).reshape((len(hr_mask_samples_list), blockz, block_width, block_height))\n",
    "# samples_flair = np.array(hr_samples_flair_list).reshape((len(hr_samples_flair_list), blockz, block_width, block_height))\n",
    "# samples_t1ce = np.array(hr_samples_t1ce_list).reshape((len(hr_samples_t1ce_list), blockz, block_width, block_height))\n",
    "# samples_t2 = np.array(hr_samples_t2_list).reshape((len(hr_samples_t2_list), blockz, block_width, block_height))\n",
    "\n",
    "#这里是分块的个数，以及每个分块的D，H，W\n",
    "samples, imagez, height, width = np.shape(samples_t1)[0], np.shape(samples_t1)[1], \\\n",
    "                                np.shape(samples_t1)[2], np.shape(samples_t1)[3]\n",
    "print(samples, imagez, height, width)#19 16 160 160\n",
    "# 5、合并和保存\n",
    "for j in range(samples):\n",
    "    #如果是多模态就要把数据通道数改一下\n",
    "    fourmodelimagearray = np.zeros((imagez, height, width, 1), np.float)\n",
    "    #保存路径\n",
    "    dataSavePath=\"./output_t1.npy\"\n",
    "    labelSavePath=\"./output_label.npy\"\n",
    "\n",
    "    # filepath1 = trainImage + \"\\\\\" + part + \"_\" + pathhgg_list[subsetindex] + \"_\" + str(patchnum[j]) + \".npy\"\n",
    "    # print(filepath1)\n",
    "    # filepath = trainMask + \"\\\\\" + part + \"_\" + pathhgg_list[subsetindex] + \"_\" + str(patchnum[j]) + \".npy\"\n",
    "    # print(filepath)\n",
    "\n",
    "    #这里只有t1，所以只用了t1模态\n",
    "    t1image = samples_t1[j, :, :, :]\n",
    "    t1image = t1image.astype(np.float)\n",
    "    fourmodelimagearray[:, :, :, 0] = t1image\n",
    "\n",
    "    # flairimage = samples_flair[j, :, :, :]\n",
    "    # flairimage = flairimage.astype(np.float)\n",
    "    # fourmodelimagearray[:, :, :, 0] = flairimage\n",
    "    # t1ceimage = samples_t1ce[j, :, :, :]\n",
    "    # t1ceimage = t1ceimage.astype(np.float)\n",
    "    # fourmodelimagearray[:, :, :, 2] = t1ceimage\n",
    "    # t2image = samples_t2[j, :, :, :]\n",
    "    # t2image = t2image.astype(np.float)\n",
    "    # fourmodelimagearray[:, :, :, 3] = t2image\n",
    "    print(fourmodelimagearray.shape)\n",
    "    \n",
    "    #保存数据为npy文件\n",
    "    np.save(dataSavePath, fourmodelimagearray)\n",
    "    \n",
    "    #创建一个空的3通道的用于放标签的数组\n",
    "    wt_tc_etMaskArray = np.zeros((imagez, height, width, 3), np.uint8)\n",
    "    mask_one_sample = mask_samples[j, :, :, :]\n",
    "    C1_Label = mask_one_sample.copy()\n",
    "    C1_Label[mask_one_sample==1]=1\n",
    "    C2_Label = mask_one_sample.copy()\n",
    "    C2_Label[mask_one_sample==2]=2\n",
    "    C3_Label = mask_one_sample.copy()\n",
    "    C3_Label[mask_one_sample==3]=3\n",
    "    wt_tc_etMaskArray[:, :, :, 0] = C1_Label\n",
    "    wt_tc_etMaskArray[:, :, :, 1] = C2_Label\n",
    "    wt_tc_etMaskArray[:, :, :, 2] = C3_Label\n",
    "    \n",
    "    #不是Brats数据集一般用不到\n",
    "    # WT_Label[mask_one_sample == 1] = 1.\n",
    "    # WT_Label[mask_one_sample == 2] = 1.\n",
    "    # WT_Label[mask_one_sample == 4] = 1.\n",
    "    # TC_Label = mask_one_sample.copy()\n",
    "    # TC_Label[mask_one_sample == 1] = 1.\n",
    "    # TC_Label[mask_one_sample == 2] = 0.\n",
    "    # TC_Label[mask_one_sample == 4] = 1.\n",
    "    # ET_Label = mask_one_sample.copy()\n",
    "    # ET_Label[mask_one_sample == 1] = 0.\n",
    "    # ET_Label[mask_one_sample == 2] = 0.\n",
    "    # ET_Label[mask_one_sample == 4] = 1.\n",
    "    # wt_tc_etMaskArray[:, :, :, 0] = WT_Label\n",
    "    # wt_tc_etMaskArray[:, :, :, 1] = TC_Label\n",
    "    # wt_tc_etMaskArray[:, :, :, 2] = ET_Label\n",
    "\n",
    "    np.save(labelSavePath, wt_tc_etMaskArray)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 160, 160, 1)\n"
     ]
    }
   ],
   "source": [
    "data=np.load(r'./output_t1.npy')\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import torch.utils.data as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "def load_label_t1w(mask_path,t1w_path,label_path):\n",
    "    t1w_data = nib.load(t1w_path).get_fdata()\n",
    "    mask_data = nib.load(mask_path).get_fdata()\n",
    "    mask_np = np.array(mask_data)\n",
    "    label_data = nib.load(label_path).get_fdata()\n",
    "    label_np = np.array(label_data)\n",
    "    print(label_np.dtype)\n",
    "    label_np[label_np==4] = 0\n",
    "    label_np[label_np==5] = 0\n",
    "    label_np[label_np==6] = 0\n",
    "    t1w_mask = np.multiply(t1w_data,mask_np)\n",
    "    print(np.unique(label_np))\n",
    "    return t1w_mask,label_np\n",
    "\n",
    "class Load_data_dbb(data.Dataset):\n",
    "    def __init__(self,mask_paths,t1w_paths,label_paths):\n",
    "        super(Load_data_dbb, self).__init__()\n",
    "        # self.load_label_t1w = load_label_t1w\n",
    "        self.mask_paths = mask_paths\n",
    "        self.t1w_paths = t1w_paths\n",
    "        self.label_paths = label_paths\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        image , mask = load_label_t1w(self.mask_paths[idx], self.t1w_paths[idx], self.label_paths[idx])\n",
    "        image_tensor = torch.from_numpy(image).float()\n",
    "        mask_tensor = torch.from_numpy(mask).long()\n",
    "        return image_tensor ,mask_tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.mask_paths)\n",
    "\n",
    "def read_paths(root_dir):\n",
    "    subjects = os.listdir(root_dir)\n",
    "    t1w_paths = []\n",
    "    mask_paths = []\n",
    "    label_paths = []\n",
    "    for subject in subjects:\n",
    "        subject_dir = os.path.join(root_dir,subject)\n",
    "        subject_files = os.listdir(subject_dir)\n",
    "        for file_dir in subject_files:\n",
    "            if('t1w' in file_dir):\n",
    "                t1w_path = subject_dir + '/' + file_dir + '/t1.nii.gz'\n",
    "                t1w_paths.append(t1w_path)\n",
    "            elif('mask' in file_dir):\n",
    "                mask_path = subject_dir + '/' + file_dir + '/mask.nii.gz'\n",
    "                mask_paths.append(mask_path)\n",
    "            elif('parcellation' in file_dir):\n",
    "                label_path= subject_dir + '/' + file_dir + '/parc.nii.gz'\n",
    "                label_paths.append(label_path)\n",
    "    # print(mask_paths)\n",
    "    return t1w_paths,mask_paths,label_paths\n",
    "root_dir=r'E:\\DBB\\DBB_SUB'\n",
    "t1w_paths,mask_paths,label_paths=read_paths(root_dir)\n",
    "train_dataset = Load_data_dbb(t1w_paths,mask_paths,label_paths)\n",
    "print(len(train_dataset))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
